{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "卷积操作得到了空间信息"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "卷积部分叫做特征提取,全连接部分叫做分类器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "光敏电阻,变成光照强度,然后组成图片,黑白的,\n",
    "光敏器件,红色传感器,绿色传感器,蓝色传感器,RGB\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "灰度级别,转换成0-255,转换成图像\n",
    "插值\n",
    "矢量图像---人工生成,圆心,边,直径,描述,放大不失真\n",
    "栅格图像---小格子,放大失真\n",
    "    Input Channel Width,Height\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "卷积运算\n",
    "Batch * N*W*H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_channels,out_channels=5,10\n",
    "width,height=100,100\n",
    "kernel_size=3\n",
    "batch_size=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input=torch.randn(batch_size,\n",
    "                  in_channels,\n",
    "                  width,\n",
    "                  height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_layer=torch.nn.Conv2d(in_channels,\n",
    "                          out_channels,\n",
    "                          kernel_size=kernel_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "output=conv_layer(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 5, 100, 100])\n"
     ]
    }
   ],
   "source": [
    "print(input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10, 98, 98])\n"
     ]
    }
   ],
   "source": [
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 5, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "print(conv_layer.weight.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "padding:kernel/2----整除向下取整"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "input=[3,4,6,5,7,\n",
    "       2,4,6,8,2,\n",
    "       1,6,7,8,4,\n",
    "       9,7,4,6,2,\n",
    "       3,7,5,4,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "input=torch.Tensor(input).view(1,1,5,5)\n",
    "conv_layer=torch.nn.Conv2d(1,1,kernel_size=3,padding=1,bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel=torch.Tensor([1,2,3,4,5,6,7,8,9]).view(1,1,3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_layer.weight.data=kernel.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "output=conv_layer(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 91., 168., 224., 215., 127.],\n",
      "          [114., 211., 295., 262., 149.],\n",
      "          [192., 259., 282., 214., 122.],\n",
      "          [194., 251., 253., 169.,  86.],\n",
      "          [ 96., 112., 110.,  68.,  31.]]]], grad_fn=<ThnnConv2DBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "input=[3,4,6,5,\n",
    "       2,4,6,8,\n",
    "       1,6,7,8,\n",
    "       9,7,4,6,\n",
    "      ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "input=torch.Tensor(input).view(1,1,4,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxpooling_layer=torch.nn.MaxPool2d(kernel_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "output=maxpooling_layer(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[4., 8.],\n",
      "          [9., 8.]]]])\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        self.conv1=torch.nn.Conv2d(1,10,kernel_size=5)\n",
    "        self.conv2=torch.nn.Conv2d(10,20,kernel_size=5)\n",
    "        self.pooling=torch.nn.MaxPool2d(2)\n",
    "        self.fc=torch.nn.Linear(320,10)\n",
    "    def forward(self,x):\n",
    "        batch_size=x.size(0)\n",
    "        x=F.relu(self.pooling(self.conv1(x)))\n",
    "        x=F.relu(self.pooling(self.conv2(x)))\n",
    "        x=x.view(batch_size,-1)\n",
    "        x=self.fc(x)\n",
    "        return x\n",
    "model=Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        self.conv1=torch.nn.Conv2d(1,10,kernel_size=5)\n",
    "        self.conv2=torch.nn.Conv2d(10,20,kernel_size=5)\n",
    "        self.pooling=torch.nn.MaxPool2d(2)\n",
    "        self.fc=torch.nn.Linear(320,10)\n",
    "    def forward(self,x):\n",
    "        batch_size=x.size(0)\n",
    "        x=F.relu(self.pooling(self.conv1(x)))\n",
    "        x=F.relu(self.pooling(self.conv2(x)))\n",
    "        x=x.view(batch_size,-1)\n",
    "        x=self.fc(x)\n",
    "        return x\n",
    "model=Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (pooling): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc): Linear(in_features=320, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define device as the first visible cuda device if we have CUDA avalible\n",
    "device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)#convert  parameters and buffers of all modules to CUDA Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    running_loss=0.0\n",
    "    for batch_idx,data in enumerate(train_loader,0):\n",
    "        inputs, target = data\n",
    "        #send the inputs and targets at every step to the GPU\n",
    "        inputs,target=inputs.to(device),target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        # forward + backward + update\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        if batch_idx % 300 == 299:\n",
    "            print('[%d, %5d] loss: %.3f' % (epoch + 1, batch_idx + 1, running_loss / 300))\n",
    "            running_loss = 0.0        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    correct=0\n",
    "    total=0\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            images, labels = data\n",
    "            images,labels=images.to(device),labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, dim=1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print('Accuracy on test set: %d %%'%(100*correct/total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
