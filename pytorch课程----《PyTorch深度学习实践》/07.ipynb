{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pytorch 中sigmoid函数是向量计算的\n",
    "为什么要转换成向量,利用并行计算的能力来提高整个运算的速度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.294118   0.487437   0.180328  ... -0.53117   -0.0333333  0.       ]\n",
      " [-0.882353  -0.145729   0.0819672 ... -0.766866  -0.666667   1.       ]\n",
      " [-0.0588235  0.839196   0.0491803 ... -0.492741  -0.633333   0.       ]\n",
      " ...\n",
      " [-0.411765   0.21608    0.180328  ... -0.857387  -0.7        1.       ]\n",
      " [-0.882353   0.266332  -0.0163934 ... -0.768574  -0.133333   0.       ]\n",
      " [-0.882353  -0.0653266  0.147541  ... -0.797609  -0.933333   1.       ]]\n"
     ]
    }
   ],
   "source": [
    "xy=np.loadtxt('data/diabetes.csv.gz',delimiter=',',dtype=np.float32)\n",
    "x_data=torch.from_numpy(xy[:,:-1])#xy[:,:-1]表示所有行,从第一列到导数第二列,左后一列不要\n",
    "y_data=torch.from_numpy(xy[:,[-1]])#表示所有行到最后一列,这个形式表示矩阵,没有中括号表示向量\n",
    "#torch.from_numpy表示创建tensor\n",
    "print(xy)\n",
    "#print(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data1=torch.from_numpy(xy[:,-1])\n",
    "#print(y_data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model,self).__init__()\n",
    "        self.Linear1=torch.nn.Linear(8,6)\n",
    "        #8和1表示输入8列,输出1列\n",
    "        self.Linear2=torch.nn.Linear(6,4)\n",
    "        self.Linear3=torch.nn.Linear(4,1)\n",
    "        self.activate=torch.nn.ReLU()\n",
    "    def forward(self,x):\n",
    "        x=self.activate(self.Linear1(x))\n",
    "        x=self.activate(self.Linear2(x))\n",
    "        x=self.activate(self.Linear3(x))\n",
    "        return x\n",
    "model=Model()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion=torch.nn.BCELoss()\n",
    "optimizer=torch.optim.SGD(model.parameters(),lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "矩阵是空间变化函数,比如y=Ax,x是N*1,y是M*1,A是M*N,\n",
    "隐层越多,对非线性的学习能力就越强,学习能力越强就把样本里边的噪声也学到了,泛化能力强,超参数搜索的方式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "隐含层数,可以把它变成高维,也可以变成低维"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "写代码:\n",
    "    要求有读文档的能力,对基础架构的理解,比如对CPU架构的理解,对主机的内存架构,操作系统的编译原理的理解\n",
    "    不是有一本书,都会了,技术更新比较快\n",
    "    新技术:快速读文档,掌握新技术的特性,\n",
    "    只会背书的话,只能背完一本,再找一本\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 18.056568145751953\n",
      "1 18.056568145751953\n",
      "2 18.056568145751953\n",
      "3 18.056568145751953\n",
      "4 18.056568145751953\n",
      "5 18.056568145751953\n",
      "6 18.056568145751953\n",
      "7 18.056568145751953\n",
      "8 18.056568145751953\n",
      "9 18.056568145751953\n",
      "10 18.056568145751953\n",
      "11 18.056568145751953\n",
      "12 18.056568145751953\n",
      "13 18.056568145751953\n",
      "14 18.056568145751953\n",
      "15 18.056568145751953\n",
      "16 18.056568145751953\n",
      "17 18.056568145751953\n",
      "18 18.056568145751953\n",
      "19 18.056568145751953\n",
      "20 18.056568145751953\n",
      "21 18.056568145751953\n",
      "22 18.056568145751953\n",
      "23 18.056568145751953\n",
      "24 18.056568145751953\n",
      "25 18.056568145751953\n",
      "26 18.056568145751953\n",
      "27 18.056568145751953\n",
      "28 18.056568145751953\n",
      "29 18.056568145751953\n",
      "30 18.056568145751953\n",
      "31 18.056568145751953\n",
      "32 18.056568145751953\n",
      "33 18.056568145751953\n",
      "34 18.056568145751953\n",
      "35 18.056568145751953\n",
      "36 18.056568145751953\n",
      "37 18.056568145751953\n",
      "38 18.056568145751953\n",
      "39 18.056568145751953\n",
      "40 18.056568145751953\n",
      "41 18.056568145751953\n",
      "42 18.056568145751953\n",
      "43 18.056568145751953\n",
      "44 18.056568145751953\n",
      "45 18.056568145751953\n",
      "46 18.056568145751953\n",
      "47 18.056568145751953\n",
      "48 18.056568145751953\n",
      "49 18.056568145751953\n",
      "50 18.056568145751953\n",
      "51 18.056568145751953\n",
      "52 18.056568145751953\n",
      "53 18.056568145751953\n",
      "54 18.056568145751953\n",
      "55 18.056568145751953\n",
      "56 18.056568145751953\n",
      "57 18.056568145751953\n",
      "58 18.056568145751953\n",
      "59 18.056568145751953\n",
      "60 18.056568145751953\n",
      "61 18.056568145751953\n",
      "62 18.056568145751953\n",
      "63 18.056568145751953\n",
      "64 18.056568145751953\n",
      "65 18.056568145751953\n",
      "66 18.056568145751953\n",
      "67 18.056568145751953\n",
      "68 18.056568145751953\n",
      "69 18.056568145751953\n",
      "70 18.056568145751953\n",
      "71 18.056568145751953\n",
      "72 18.056568145751953\n",
      "73 18.056568145751953\n",
      "74 18.056568145751953\n",
      "75 18.056568145751953\n",
      "76 18.056568145751953\n",
      "77 18.056568145751953\n",
      "78 18.056568145751953\n",
      "79 18.056568145751953\n",
      "80 18.056568145751953\n",
      "81 18.056568145751953\n",
      "82 18.056568145751953\n",
      "83 18.056568145751953\n",
      "84 18.056568145751953\n",
      "85 18.056568145751953\n",
      "86 18.056568145751953\n",
      "87 18.056568145751953\n",
      "88 18.056568145751953\n",
      "89 18.056568145751953\n",
      "90 18.056568145751953\n",
      "91 18.056568145751953\n",
      "92 18.056568145751953\n",
      "93 18.056568145751953\n",
      "94 18.056568145751953\n",
      "95 18.056568145751953\n",
      "96 18.056568145751953\n",
      "97 18.056568145751953\n",
      "98 18.056568145751953\n",
      "99 18.056568145751953\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(100):\n",
    "    y_pred=model(x_data)\n",
    "    loss=criterion(y_pred,y_data)\n",
    "    print(epoch,loss.item())\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for \n",
    "plt.plot(epoch,loss)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
